{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Beta: [-0.49854674 -0.09891729]\n",
      "True Beta: [-0.5, -0.1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "\n",
    "# Simulating a dataset with alternative-specific variables, adding Gumbel noise for realism\n",
    "np.random.seed(42)\n",
    "N = 100000  # Number of individuals\n",
    "J = 3    # Number of alternatives (Car, Bus, Train)\n",
    "\n",
    "# Alternative-specific attributes (Price, Travel Time) - same across individuals\n",
    "prices = np.array([15, 5, 10])  # Price for Car, Bus, Train\n",
    "travel_times = np.array([30, 45, 40])  # Travel time for Car, Bus, Train\n",
    "\n",
    "# True preference weights (Beta values)\n",
    "beta_price = -0.5  # Base price sensitivity\n",
    "beta_time = -0.1  # Sensitivity to travel time\n",
    "\n",
    "# Compute utilities\n",
    "U = beta_price * prices + beta_time * travel_times  # Shape (J,)\n",
    "U = np.tile(U, (N, 1))  # Repeat for all individuals (N, J)\n",
    "\n",
    "# Add Gumbel-distributed noise to utilities\n",
    "epsilon = np.random.gumbel(0, .1, size=(N, J))  # Shape (N, J)\n",
    "U += epsilon\n",
    "\n",
    "# Simulate choices using softmax probabilities\n",
    "def softmax(U):\n",
    "    exp_U = np.exp(U - np.max(U, axis=1, keepdims=True))  # Prevent overflow\n",
    "    return exp_U / exp_U.sum(axis=1, keepdims=True)\n",
    "\n",
    "P = softmax(U)  # Choice probabilities\n",
    "choices = np.array([np.random.choice(J, p=P[i]) for i in range(N)])\n",
    "\n",
    "# Organizing data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Individual\": np.repeat(np.arange(N), J),\n",
    "    \"Mode\": np.tile([\"Car\", \"Bus\", \"Train\"], N),\n",
    "    \"Chosen\": (np.tile(np.arange(J), N) == np.repeat(choices, J)).astype(int),\n",
    "    \"Price\": np.tile(prices, N),\n",
    "    \"TravelTime\": np.tile(travel_times, N)\n",
    "})\n",
    "\n",
    "# Log-likelihood function for estimation\n",
    "def log_likelihood(beta, X, choices):\n",
    "    U = X @ beta  # Compute utilities\n",
    "    P = softmax(U)  # Compute probabilities\n",
    "    chosen_probs = P[np.arange(N), choices]  # Get probability of chosen option\n",
    "    return -np.sum(np.log(chosen_probs))  # Negative log-likelihood\n",
    "\n",
    "# Prepare data for estimation\n",
    "X_columns = [\"Price\", \"TravelTime\"]\n",
    "X = df[X_columns].values.reshape(N, J, -1)  # Reshape for estimation\n",
    "choices = df[\"Chosen\"].values.reshape(N, J).argmax(axis=1)  # Convert to choice indices\n",
    "\n",
    "# Estimating parameters using MLE\n",
    "initial_beta = np.zeros(X.shape[2])  # Start with zero coefficients\n",
    "result = opt.minimize(log_likelihood, initial_beta, args=(X, choices), method='BFGS')\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated Beta:\", result.x)\n",
    "print(\"True Beta:\", [beta_price, beta_time])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
